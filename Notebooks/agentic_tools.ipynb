{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1019a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in ./chatbot/lib/python3.13/site-packages (0.14.5)\n",
      "Requirement already satisfied: llama-index-llms-openai in ./chatbot/lib/python3.13/site-packages (0.6.4)\n",
      "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in ./chatbot/lib/python3.13/site-packages (from llama-index) (0.5.3)\n",
      "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.5 in ./chatbot/lib/python3.13/site-packages (from llama-index) (0.14.5)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in ./chatbot/lib/python3.13/site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in ./chatbot/lib/python3.13/site-packages (from llama-index) (0.9.4)\n",
      "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in ./chatbot/lib/python3.13/site-packages (from llama-index) (0.5.4)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in ./chatbot/lib/python3.13/site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./chatbot/lib/python3.13/site-packages (from llama-index) (3.9.2)\n",
      "Requirement already satisfied: openai<2,>=1.108.1 in ./chatbot/lib/python3.13/site-packages (from llama-index-llms-openai) (1.109.1)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (3.13.0)\n",
      "Requirement already satisfied: aiosqlite in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2025.9.0)\n",
      "Requirement already satisfied: httpx in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<3,>=2 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2.7.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (3.5)\n",
      "Requirement already satisfied: numpy in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2.3.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (10.4.0)\n",
      "Requirement already satisfied: platformdirs in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2.12.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./chatbot/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.5->llama-index) (2.0.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./chatbot/lib/python3.13/site-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./chatbot/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./chatbot/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./chatbot/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./chatbot/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./chatbot/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./chatbot/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./chatbot/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.22.0)\n",
      "Requirement already satisfied: griffe in ./chatbot/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in ./chatbot/lib/python3.13/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.1.6)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in ./chatbot/lib/python3.13/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.14.2)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in ./chatbot/lib/python3.13/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
      "Requirement already satisfied: pandas<2.3.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<7,>=5.1.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.1.3)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./chatbot/lib/python3.13/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./chatbot/lib/python3.13/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-workflows<3,>=2->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./chatbot/lib/python3.13/site-packages (from openai<2,>=1.108.1->llama-index-llms-openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./chatbot/lib/python3.13/site-packages (from openai<2,>=1.108.1->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./chatbot/lib/python3.13/site-packages (from openai<2,>=1.108.1->llama-index-llms-openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in ./chatbot/lib/python3.13/site-packages (from openai<2,>=1.108.1->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./chatbot/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<2,>=1.108.1->llama-index-llms-openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./chatbot/lib/python3.13/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.5->llama-index) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in ./chatbot/lib/python3.13/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./chatbot/lib/python3.13/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./chatbot/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./chatbot/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./chatbot/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./chatbot/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in ./chatbot/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./chatbot/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.4.2)\n",
      "Requirement already satisfied: llama-cloud==0.1.35 in ./chatbot/lib/python3.13/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in ./chatbot/lib/python3.13/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.54 in ./chatbot/lib/python3.13/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: click<9,>=8.1.7 in ./chatbot/lib/python3.13/site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.3.0)\n",
      "Requirement already satisfied: python-dotenv<2,>=1.0.1 in ./chatbot/lib/python3.13/site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
      "Requirement already satisfied: joblib in ./chatbot/lib/python3.13/site-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./chatbot/lib/python3.13/site-packages (from nltk>3.8.1->llama-index) (2025.9.18)\n",
      "Requirement already satisfied: six>=1.5 in ./chatbot/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./chatbot/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./chatbot/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in ./chatbot/lib/python3.13/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./chatbot/lib/python3.13/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./chatbot/lib/python3.13/site-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./chatbot/lib/python3.13/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.5->llama-index) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in ./chatbot/lib/python3.13/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./chatbot/lib/python3.13/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.workflow import Context\n",
    "from llama_index.core.tools import FunctionTool\n",
    "import asyncio\n",
    "import os\n",
    "%pip install llama-index llama-index-llms-openai\n",
    "from llama_index.llms.gemini import Gemini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db5fee",
   "metadata": {},
   "source": [
    "# Add to cart is working now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b26f3fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12759/3986912147.py:1: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
      "  llm = Gemini(\n"
     ]
    }
   ],
   "source": [
    "llm = Gemini(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=\"AIzaSyBUMw3It8zFhNJgkPmVo_0OFQFndduDsYM\",  # uses GOOGLE_API_KEY env var by default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21f6359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "Settings.llm = Ollama(\n",
    "    model=\"llama3.2:1B\",\n",
    "    request_timeout=360.0,\n",
    "    # Manually set the context window to limit memory usage\n",
    "    context_window=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75845501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-5-nano\",\n",
    "    api_key=\"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\",  # uses OPENAI_API_KEY env var by default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e363508",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d92b5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = []\n",
    "wishlist = []\n",
    "\n",
    "# Make the search function synchronous\n",
    "def search_furniture_products(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for furniture products in the store inventory.\n",
    "    \n",
    "    Use this when the user asks about:\n",
    "    - Product details (materials, dimensions, colors, features)\n",
    "    - Prices and availability\n",
    "    - Specific furniture items (sofas, tables, chairs, beds, etc.)\n",
    "    - Comparisons between products\n",
    "    - Product recommendations\n",
    "    \n",
    "    Args:\n",
    "        query: Natural language question about furniture products\n",
    "        \n",
    "    Returns:\n",
    "        Detailed information about the requested furniture items\n",
    "        \n",
    "    Examples:\n",
    "    - \"What sofas do you have under $500?\"\n",
    "    - \"Tell me about leather recliners\"\n",
    "    - \"What's the material of the Oak Dining Table?\"\n",
    "    \"\"\"\n",
    "    # Use synchronous query instead\n",
    "    response = query_engine.query(query)\n",
    "    return str(response)\n",
    "\n",
    "def addToCart(item)->str:\n",
    "    \"\"\"Useful for adding an item to the cart\"\"\"\n",
    "    cart.append(item)\n",
    "    return \"Item added to the cart\"\n",
    "\n",
    "def addToWishlist(item)->str:\n",
    "    \"\"\"Useful for adding an item to the wishlist\"\"\"\n",
    "    wishlist.append(item)\n",
    "    return \"Item added to the wishlist\"\n",
    "\n",
    "# Create an agent workflow with our calculator tool\n",
    "agent = FunctionAgent(\n",
    "    tools=[addToCart,search_furniture_products,addToWishlist],\n",
    "    # llm=Ollama(model=\"llama3.2:1B\",thinking=False),\n",
    "    llm=llm,\n",
    "    system_prompt=\"\"\"You are a helpful furniture store assistant. \n",
    "\n",
    "Your capabilities:\n",
    "1. **Search products**: Use search_furniture_products to answer questions about furniture items, prices, materials, availability, or features\n",
    "2. **Add to cart**: Use add_to_cart when customers want to purchase items\n",
    "3. **Add to wishlist**: Use add_to_wishlist when customers want to save items for later\n",
    "\n",
    "Important guidelines:\n",
    "- ALWAYS use search_furniture_products FIRST when users ask about products, prices, or details\n",
    "- Only add items to cart/wishlist AFTER the customer has seen product information\n",
    "- Use the exact product names returned from search results\n",
    "- Be helpful and ask clarifying questions if needed\n",
    "\n",
    "Example flow:\n",
    "User: \"What sofas do you have?\"\n",
    "→ Use search_furniture_products(\"sofas available\")\n",
    "→ Present results to user\n",
    "User: \"I'll take the Modern Leather Sofa\"\n",
    "→ Use add_to_cart(\"Modern Leather Sofa\")\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59bde583",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebe2e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "respnse = await agent.run(\"Add trimmer to the cart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47407755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='Item added to the cart.')]), structured_response=None, current_agent_name='Agent', raw={'model': 'qwen3:0.6b', 'created_at': '2025-10-22T05:51:08.690907173Z', 'done': True, 'done_reason': 'stop', 'total_duration': 389452081, 'load_duration': 49095859, 'prompt_eval_count': 452, 'prompt_eval_duration': 236327070, 'eval_count': 7, 'eval_duration': 87262190, 'message': Message(role='assistant', content='', thinking=None, images=None, tool_name=None, tool_calls=None), 'usage': {'prompt_tokens': 452, 'completion_tokens': 7, 'total_tokens': 459}}, tool_calls=[ToolCallResult(tool_name='addToCart', tool_kwargs={'item': 'trimmer'}, tool_id='addToCart', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='Item added to the cart')], tool_name='addToCart', raw_input={'args': (), 'kwargs': {'item': 'trimmer'}}, raw_output='Item added to the cart', is_error=False), return_direct=False)], retry_messages=[])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respnse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d23562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trimmer']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e815fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.run(\"What are the products available in your furniture store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff397bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Here are some of our products with a rating greater than 4.3 and currently in stock:\n",
      "\n",
      "*   **Modern Wooden Dining Table**\n",
      "    *   Category: Dining\n",
      "    *   Price: 18999 INR\n",
      "    *   Material: Sheesham Wood\n",
      "    *   Color: Walnut Brown\n",
      "    *   Rating: 4.6\n",
      "\n",
      "*   **ErgoComfort Office Chair**\n",
      "    *   Category: Office\n",
      "    *   Price: 7999 INR\n",
      "    *   Material: Mesh & Metal\n",
      "    *   Color: Black\n",
      "    *   Rating: 4.4\n",
      "\n",
      "Is there anything else I can help you with regarding these products, or would you like to see other items?\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "406cb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.run(\"What dining tables you have in your furniture store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05066da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Great! The \"Glass Top Dining Table\" sounds like a good option.\n",
      "\n",
      "Would you like to know more details about the \"Glass Top Dining Table,\" or would you like to add it to your cart or wishlist?\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d166128",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.run(\"What products do you have in your furniture store?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c71f250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='None of the tools provided can be used to answer the question about the products available in the furniture store.')])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7c5bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await query_engine.aquery(\"what products do you have in your furniture store\")\n",
    "resp = str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5caa6ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking, \"what products do you have in your furniture store?\" and they provided a list of products in the Details.txt file. Let me check the context to make sure I don't include any prior knowledge.\n",
      "\n",
      "Looking at the context, there are five entries in the file: FUR001, FUR002, FUR003, FUR004, and FUR005. Each entry has details like category, price, etc. The user wants to know the products available. Since the context is the list provided, I need to list them all without adding any information I don't have. The answer should just be the product names in the list. Let me make sure there's no mention of other products or categories beyond the ones listed. Yep, all five are in the list. So the answer is the names of each product as listed.\n",
      "</think>\n",
      "\n",
      "The furniture store has the following products:  \n",
      "- Modern Wooden Dining Table  \n",
      "- ErgoComfort Office Chair  \n",
      "- Velvet Queen Size Bed  \n",
      "- Glass Top Coffee Table  \n",
      "- Bookshelf with Cabinet\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "915138d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FunctionAgent' object has no attribute 'achat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43machat\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mwhat products do you have in your furniture store?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/aumoza/Strg_1/Freelance/personal/Chatbot/chatbot/lib/python3.13/site-packages/pydantic/main.py:1026\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'FunctionAgent' object has no attribute 'achat'"
     ]
    }
   ],
   "source": [
    "response = await agent.achat(\"what products do you have in your furniture store?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27246ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e11fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
